{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "(train_input, train_target), (test_input, test_target) = \\\n",
    "keras.datasets.mnist.load_data()\n",
    "\n",
    "train_scaled = train_input.reshape(-1, 28, 28, 1) / 255.0\n",
    "\n",
    "# 검증세트\n",
    "train_scaled, val_scaled, train_target, val_target = \\\n",
    "train_test_split(train_scaled, train_target, test_size=.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 28, 28, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 14, 14, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 3136)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 100)               313700    \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                1010      \n",
      "=================================================================\n",
      "Total params: 333,526\n",
      "Trainable params: 333,526\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 모델 생성\n",
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Conv2D(32, kernel_size=3, activation='relu', # 층을 늘릴거면 커널 개수를 늘려도 됨.. 64, 128, 256...\n",
    "                              padding='same', input_shape=(28, 28, 1)))\n",
    "model.add(keras.layers.MaxPooling2D(2))\n",
    "model.add(keras.layers.Conv2D(64, kernel_size=3, activation='relu', padding='same'))\n",
    "model.add(keras.layers.MaxPooling2D(2))\n",
    "\n",
    "# 밀집층, 완전연결층\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(100, activation='relu'))\n",
    "model.add(keras.layers.Dropout(0.4))\n",
    "model.add(keras.layers.Dense(10, activation='softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 48000 samples\n",
      "Epoch 1/10\n",
      "48000/48000 [==============================] - 28s 592us/sample - loss: 0.2284 - accuracy: 0.9299\n",
      "Epoch 2/10\n",
      "48000/48000 [==============================] - 28s 592us/sample - loss: 0.0865 - accuracy: 0.9740\n",
      "Epoch 3/10\n",
      "48000/48000 [==============================] - 27s 560us/sample - loss: 0.0605 - accuracy: 0.9822\n",
      "Epoch 4/10\n",
      "48000/48000 [==============================] - 27s 558us/sample - loss: 0.0485 - accuracy: 0.9849\n",
      "Epoch 5/10\n",
      "48000/48000 [==============================] - 27s 560us/sample - loss: 0.0399 - accuracy: 0.9877\n",
      "Epoch 6/10\n",
      "48000/48000 [==============================] - 28s 573us/sample - loss: 0.0318 - accuracy: 0.9901\n",
      "Epoch 7/10\n",
      "48000/48000 [==============================] - 27s 554us/sample - loss: 0.0285 - accuracy: 0.9909\n",
      "Epoch 8/10\n",
      "48000/48000 [==============================] - 26s 549us/sample - loss: 0.0245 - accuracy: 0.9922\n",
      "Epoch 9/10\n",
      "48000/48000 [==============================] - 27s 555us/sample - loss: 0.0216 - accuracy: 0.9930\n",
      "Epoch 10/10\n",
      "48000/48000 [==============================] - 26s 550us/sample - loss: 0.0177 - accuracy: 0.9945\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2030c52fba8>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model.fit(train_scaled, train_target, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = Image.open('D:/python3/data/7p.png')\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x2030ef7de48>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 28)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "image = ((np.array(image) / 255.0 ) -1 ) *1  # png타입을 스케일링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.0349104 , 0.1259725 , 0.01714758, 0.21651185, 0.02003571,\n",
       "        0.3057587 , 0.06040382, 0.02933895, 0.11310337, 0.07681704]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = model.predict(np.reshape(image, (1, 28, 28, 1)))  # 하나의 데이터 불러올 때,,\n",
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.photopea.com\n",
    "무료 포토샵"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3057587"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(a[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(a[0]).index(max(a[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "http://datascienceschool.net/intro.html"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
